import os
import requests
from gtts import gTTS
from dotenv import load_dotenv
import gradio as gr

# ğŸ” Charger le token Hugging Face depuis le fichier .env
load_dotenv()
API_TOKEN = os.getenv("HF_TOKEN")

# ğŸ”— URL du modÃ¨le GPT4All hÃ©bergÃ© sur Hugging Face
API_URL = "https://api-inference.huggingface.co/models/nomic-ai/gpt4all-j"

# ğŸ§  Fonction pour interroger GPT4All
def generate_response(prompt: str) -> str:
    headers = {"Authorization": f"Bearer {API_TOKEN}"}
    payload = {
        "inputs": prompt,
        "parameters": {
            "temperature": 0.7,
            "max_new_tokens": 100
        }
    }

    try:
        response = requests.post(API_URL, headers=headers, json=payload)
        result = response.json()

        if isinstance(result, list) and "generated_text" in result[0]:
            return result[0]["generated_text"]
        return "DÃ©solÃ©, je n'ai pas compris ta question."
    except Exception as error:
        return f"Erreur lors de la gÃ©nÃ©ration : {str(error)}"

# ğŸ”Š Fonction principale du chatbot
def chat_fn(message: str, history: list) -> tuple:
    response = generate_response(message)

    # GÃ©nÃ©rer la rÃ©ponse vocale
    tts = gTTS(text=response, lang='fr')
    audio_path = "reponse.mp3"
    tts.save(audio_path)

    # Mettre Ã  jour l'historique du chat
    history.append((message, response))
    return history, audio_path

# ğŸ’¬ Interface Gradio faÃ§on messagerie
gr.ChatInterface(
    fn=chat_fn,
    title="Assistant IA vocal de Nass ğŸ’¬",
    description="Discute avec ton assistant comme dans une messagerie. Il te rÃ©pond Ã  l'Ã©crit et Ã  l'oral.",
    additional_inputs=gr.Audio(sources=["microphone"], type="filepath", label="RÃ©ponse vocale"),
    theme="soft"
).launch()