import os
import requests
from gtts import gTTS
import gradio as gr
from dotenv import load_dotenv

# ğŸ” Charger les variables d'environnement depuis le fichier .env
load_dotenv()
API_TOKEN = os.getenv("HF_TOKEN")

# ğŸ”— URL du modÃ¨le GPT4All hÃ©bergÃ© sur Hugging Face
API_URL = "https://api-inference.huggingface.co/models/nomic-ai/gpt4all-j"

# ğŸ§  Fonction pour interroger l'API Hugging Face
def generate_response(prompt):
    headers = {
        "Authorization": f"Bearer {API_TOKEN}"
    }
    payload = {
        "inputs": prompt,
        "parameters": {
            "temperature": 0.7,
            "max_new_tokens": 100
        }
    }

    try:
        response = requests.post(API_URL, headers=headers, json=payload)
        result = response.json()

        # VÃ©rifie si la rÃ©ponse est bien structurÃ©e
        if isinstance(result, list) and "generated_text" in result[0]:
            return result[0]["generated_text"]
        else:
            return "DÃ©solÃ©, je n'ai pas pu gÃ©nÃ©rer de rÃ©ponse."
    except Exception as e:
        return f"Erreur : {str(e)}"

# ğŸ”Š Fonction principale appelÃ©e par Gradio
def assistant(question):
    response = generate_response(question)

    # GÃ©nÃ©rer le fichier audio avec gTTS
    tts = gTTS(text=response, lang='fr')
    audio_path = "reponse.mp3"
    tts.save(audio_path)

    return response, audio_path

# ğŸ™ï¸ Interface Gradio avec texte + audio
gr.Interface(
    fn=assistant,
    inputs=gr.Textbox(label="Pose ta question ici"),
    outputs=[
        gr.Textbox(label="RÃ©ponse Ã©crite"),
        gr.Audio(label="RÃ©ponse vocale", type="filepath")
    ],
    title="Assistant IA vocal de Nass ğŸ§",
    description="Pose une question et Ã©coute la rÃ©ponse gÃ©nÃ©rÃ©e par GPT4All"
).launch()